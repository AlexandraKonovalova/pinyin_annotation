{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinyin annotators for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: g2pc in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (0.9.9.3)\n",
      "Requirement already satisfied: pkuseg>=0.0.22 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from g2pc) (0.0.25)\n",
      "Requirement already satisfied: sklearn-crfsuite>=0.3.6 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from g2pc) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from pkuseg>=0.0.22->g2pc) (1.16.5)\n",
      "Requirement already satisfied: cython in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from pkuseg>=0.0.22->g2pc) (0.29.14)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from sklearn-crfsuite>=0.3.6->g2pc) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from sklearn-crfsuite>=0.3.6->g2pc) (4.36.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from sklearn-crfsuite>=0.3.6->g2pc) (0.8.7)\n",
      "Requirement already satisfied: six in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from sklearn-crfsuite>=0.3.6->g2pc) (1.12.0)\n",
      "Requirement already satisfied: xpinyin in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (0.7.6)\n",
      "Requirement already satisfied: pypinyin in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (0.40.0)\n",
      "Requirement already satisfied: g2pM in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (0.1.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install g2pc\n",
    "!pip install xpinyin\n",
    "!pip install pypinyin\n",
    "!pip install g2pM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2pc import G2pC\n",
    "from g2pc import G2pCFH\n",
    "from g2pc import G2pCUD\n",
    "from g2pM import G2pM\n",
    "from xpinyin import Pinyin\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "import pypinyin\n",
    "import re\n",
    "\n",
    "g2p = G2pC()\n",
    "g2pFH = G2pCFH()\n",
    "g2pUD = G2pCUD()\n",
    "g2pm = G2pM()\n",
    "xp = Pinyin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = '，。 “：？！ ”·；———'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "\n",
    "with open('test.txt', 'r', encoding='utf-8') as f:\n",
    "    test = [line.strip() for line in f.readlines()]\n",
    "with open('target_new.txt', 'r', encoding='utf-8') as f:\n",
    "    target = [line.strip() for line in f.readlines()]\n",
    "    num = re.compile('.+?\\d')\n",
    "    target = [re.findall(num, i) for i in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sent = len(target)\n",
    "N = sum(len(line) for line in target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G2pC with fine-tuning for different pos-taggers and G2pM\n",
    "\n",
    "def prediction_g2p(pos='pku', model='g2pc'):\n",
    "    res = []\n",
    "    for sent in test:\n",
    "        if model == 'g2pm':\n",
    "            ann = [word for word in g2pm(sent, tone=True, char_split=False) if word not in PUNCT]\n",
    "        else:\n",
    "            if pos == 'FH':\n",
    "                ann = [word[2] for word in g2pFH(sent) if word[2] not in PUNCT]\n",
    "            elif pos == 'UD':\n",
    "                ann = [word[2] for word in g2pUD(sent) if word[2] not in PUNCT]\n",
    "            else:\n",
    "                ann = [word[2] for word in g2p(sent) if word[2] not in PUNCT]\n",
    "        ann = ''.join(ann).replace(' ', '')\n",
    "        res.append(re.findall(num, ann))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xpinyin \n",
    "\n",
    "def prediction_xp():\n",
    "    res = []\n",
    "    for sent in test:\n",
    "        ann = xp.get_pinyin(sent, ' ', tone_marks='numbers').split()\n",
    "        ann = [word for word in ann if word not in PUNCT]\n",
    "        res.append(ann)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pypinyin\n",
    "\n",
    "def prediction_pyp():\n",
    "    res = []\n",
    "    for sent in test:\n",
    "        ann = pinyin(sent, style=pypinyin.TONE3, heteronym=False)\n",
    "        ann = [word[0] for word in ann if word[0] not in PUNCT]\n",
    "        res.append(ann)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent of true annotated characters\n",
    "\n",
    "def metrics(name, res):\n",
    "    per = 0\n",
    "    for pred, true in zip(res, target):\n",
    "        for pr, tr in zip(pred, true):\n",
    "            if pr == tr:\n",
    "                per += 1\n",
    "    return name, str(per/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.DataFrame(columns=['model', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n",
      "loading vocabulary file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\vocab.txt\n",
      "Load pre-trained BERT parameters from file C:\\Users\\Xiaomi\\.fastNLP\\fasthan\\fasthan_base\\model.bin.\n"
     ]
    }
   ],
   "source": [
    "result.loc[0] = metrics('G2pC-pkuseg', prediction_g2p())\n",
    "result.loc[1] = metrics('G2pC-FastHan', prediction_g2p('FH'))\n",
    "result.loc[2] = metrics('G2pC-UDPipe', prediction_g2p('UD'))\n",
    "result.loc[3] = metrics('G2pM-pkuseg', prediction_g2p(model='g2pm'))\n",
    "result.loc[4] = metrics('xpinyin', prediction_xp())\n",
    "result.loc[5] = metrics('pypinyin', prediction_pyp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>G2pC-pkuseg</td>\n",
       "      <td>0.9029982363315696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>G2pC-FastHan</td>\n",
       "      <td>0.8994708994708994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>G2pC-UDPipe</td>\n",
       "      <td>0.8800705467372134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>G2pM-pkuseg</td>\n",
       "      <td>0.8871252204585538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xpinyin</td>\n",
       "      <td>0.8306878306878307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>pypinyin</td>\n",
       "      <td>0.7742504409171076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model            accuracy\n",
       "0   G2pC-pkuseg  0.9029982363315696\n",
       "1  G2pC-FastHan  0.8994708994708994\n",
       "2   G2pC-UDPipe  0.8800705467372134\n",
       "3   G2pM-pkuseg  0.8871252204585538\n",
       "4       xpinyin  0.8306878306878307\n",
       "5      pypinyin  0.7742504409171076"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
